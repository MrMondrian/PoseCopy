#!/usr/bin/env python3

import rospy
import math
import rosparam
import argparse

from std_msgs.msg import Float64MultiArray, MultiArrayLayout, MultiArrayDimension
#from posegrab import *
#from kortex_driver.srv import *
#from kortex_driver.msg import *




#!/usr/bin/env python3

# -*- coding: utf-8 -*-
import cv2
import numpy as np
import mediapipe as mp
from mediapipe.python.solutions.pose import PoseLandmark

"""mediapipe_pose.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uCuA6We9T5r0WljspEHWPHXCT_2bMKUy

Usage example of MediaPipe Pose Solution API in Python (see also http://solutions.mediapipe.dev/pose).
"""


"""Upload any image that that has a person. We take two example images from the web: https://unsplash.com/photos/v4zceVZ5HK8 and https://unsplash.com/photos/e_rhazQLaSs.

"""


mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils 
mp_drawing_styles = mp.solutions.drawing_styles


class PoseCapture:


    def __init__(self,video=None):
        self.DESIRED_HEIGHT = 480
        self.DESIRED_WIDTH = 480
        if video == None:
            self.cap = cv2.VideoCapture(0)
        else:
            self.cap = cv2.VideoCapture(video)


    def resize_and_show(self, image):
        h, w = image.shape[:2]
        if h < w:
            img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))
        else:
            img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))
        cv2.imshow("",img)

    def angle(self, v1,v2,z_scale):
        v1[-1] /= z_scale
        v2[-1] /= z_scale
        dot = sum([v1[i] * v2[i] for i in range(len(v1))])
        norm1 = math.dist([0]*len(v1),v1)
        norm2 = math.dist([0]*len(v1),v2)
        #print(dot/(norm1*norm2))
        return math.acos(dot/(norm1*norm2))


    def landmarks_to_dict(self, landmarks):
        out = []
        # print("##############################")
        # print(landmarks.landmark)
        for (i,lm) in enumerate(landmarks.landmark):
            out.append(lm)
        return out

    def dict_to_list(self, d):
        return [d.x,d.y,d.z]

    def elbow_angle(self, results):
        landmarks = results.pose_world_landmarks
        lm_dict = self.landmarks_to_dict(landmarks)
        wrist = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_WRIST])
        elbow = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_ELBOW])
        shoulder = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_SHOULDER])

        v1 = [shoulder[i] - elbow[i] for i in range(3)]
        v2 = [wrist[i] - elbow[i] for i in range(3)]
        return self.angle(v1,v2,30)

    def shoulder_angle(self, results):
        landmarks = results.pose_world_landmarks
        lm_dict = self.landmarks_to_dict(landmarks)
        hip = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_HIP])
        elbow = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_ELBOW])
        shoulder = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_SHOULDER])

        v1 = [elbow[i] - shoulder[i] for i in range(3)]
        v2 = [hip[i] - shoulder[i] for i in range(3)]
        return self.angle(v1,v2,15)

    def shoulder_rotation(self, results):
        landmarks = results.pose_world_landmarks
        lm_dict = self.landmarks_to_dict(landmarks)
        elbow = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_ELBOW])
        shoulder = self.dict_to_list(lm_dict[PoseLandmark.RIGHT_SHOULDER])

        v1 = [elbow[0] - shoulder[0], elbow[2] - shoulder[2]]
        v2 = [1,0]

        return self.angle(v1,v2,7)



    def angles(self):
        with mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
        model_complexity=2) as pose:
            while self.cap.isOpened():
                success, image = self.cap.read()
                print(success)
                if not success:
                    print("Ignoring empty camera frame.")
                    # If loading a video, use 'break' instead of 'continue'.
                    continue

                image.flags.writeable = False
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                results = pose.process(image)
                yield [self.shoulder_rotation(results),abs(3.14 -self.shoulder_angle(results)),abs(3.14 - self.elbow_angle(results)),0,0,0]
            self.cap.release()
            #print(elbow_angle(results))
            #print(shoulder_angle(results))
            # if(results.pose_world_landmarks and results.pose_world_landmarks.landmark):
            #   print("eblow: {}, shoulder: {}, roations: {} ".format(elbow_angle(results),shoulder_angle(results),shoulder_rotation(results)))
            #elbow_angle(results)
            #print(results.pose_landmarks)
            # print(mp_pose.POSE_CONNECTIONS)
            # Draw the pose annotation on the image.
            # image.flags.writeable = True
            #print(elbow_angle(results))
            # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            # mp_drawing.draw_landmarks(
            #     image,
            #     results.pose_landmarks,
            #     mp_pose.POSE_CONNECTIONS,
            #     landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
            # #Flip the image horizontally for a selfie-view display.
            # cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))
            # if cv2.waitKey(5) & 0xFF == 27:
            #   break
            # mp_drawing.plot_landmarks(
            #     results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)
    def angle_from_image(self,path):
        with mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
        model_complexity=2) as pose:
            image = cv2.imread(path, cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = pose.process(image)
            return [self.shoulder_rotation(results),abs(3.14 -self.shoulder_angle(results)),abs(3.14 - self.elbow_angle(results)),0,0,0]
        


class BaseController:
    def __init__(self, activate: bool = False):

        posecap = PoseCapture(video="/home/anthony/comp400/sim/kinova-arm/catkin_ws/src/base_controller/scripts/example.mp4")
        self.grab = posecap.angles()
        self.image_angles = posecap.angle_from_image('/home/anthony/comp400/sim/kinova-arm/catkin_ws/src/base_controller/scripts/example2.jpg')
        
        # read config files
        self.is_activated = activate
        #self.__config_file_address = f'../config/basic_config.yaml'
        #self.__configs = rosparam.load_file(self.__config_file_address,
        #                                    default_namespace="base_controller")[0][0]


        # display the config with a demonstration for try/catch structures
        # try:
        #     rospy.loginfo(f'Publishing to: {self.__configs["joint_position_controller_topic"]}')
        # except KeyError:
        #     rospy.logwarn('Error reading configuration: joint_position_controller_topic')

        # create a publisher, this is where you should publish messages to joint controllers
        self.__velocity_publisher = rospy.Publisher("gen3_lite/joint_group_position_controller/command",
                                                    Float64MultiArray, queue_size=10)
        
        try:
            rospy.init_node('controller')


            # Init the services
            # rospy.wait_for_service("read_all_devices", 0.5)
            # self.read_all_devices = rospy.ServiceProxy("read_all_devices", ReadAllDevices)

            # rospy.wait_for_service("set_device_id", 0.5)
            # self.set_device_id = rospy.ServiceProxy("set_device_id", SetDeviceID)

            # rospy.wait_for_service("clear_faults", 0.5)
            # self.clear_faults = rospy.ServiceProxy("clear_faults", ActuatorConfig_ClearFaults)


            # rospy.wait_for_service("read_action")
            # self.read_action = rospy.ServiceProxy("read_action", ReadAction)

            # rospy.wait_for_service("execute_action")
            # self.execute_action = rospy.ServiceProxy("execute_action", ExecuteAction)

            # rospy.wait_for_service("set_cartesian_rf")
            # self.set_cartesian_reference_frame = rospy.ServiceProxy("set_cartesian_rf", SetCartesianReferenceFrame)

            # rospy.wait_for_service("validate_waypoint_list")
            # self.validate_waypoint_list = rospy.ServiceProxy("validate_waypoint_list", ValidateWaypointList)

        except:
            self.is_init_success = False
        else:
            self.is_init_success = True
    def loop_video(self):
        angles = next(self.grab,None)
        # if angles == None:
        #     self.activated = False
        #     return
        pub = [1.5]*6
        if angles != None:
            pub[2] = angles[2]
        print("angles {}".format(angles))
        #pub[2] = 0
        # print(angles)
        self.publish_joints(pub)

    def loop_image(self):
        pub = [0]*6
        pub[0] = self.image_angles[0]
        pub[1] = self.image_angles[1]
        pub[2] = self.image_angles[2]

        self.image_angles[0] = 4.2
        #print(pub)
        self.publish_joints(pub)


    def publish_joints(self,angles):
        dim = MultiArrayDimension()
        dim.label = "angles"
        dim.size = 6
        dim.stride = 1
        layout = MultiArrayLayout([dim],0)
        self.__velocity_publisher.publish(Float64MultiArray(layout,angles))
#         self.last_action_notif_type = None

#         req = ExecuteActionRequest()

#         trajectory = WaypointList()
#         waypoint = Waypoint()
#         angularWaypoint = AngularWaypoint()

#         # Angles to send the arm to vertical position (all zeros)
#         for _ in range(self.degrees_of_freedom):
#             angularWaypoint.angles.append(0.0)

#         # Each AngularWaypoint needs a duration and the global duration (from WaypointList) is disregarded. 
#         # If you put something too small (for either global duration or AngularWaypoint duration), the trajectory will be rejected.
#         angular_duration = 0
#         angularWaypoint.duration = angular_duration

#         # Initialize Waypoint and WaypointList
#         waypoint.oneof_type_of_waypoint.angular_waypoint.append(angularWaypoint)
#         trajectory.duration = 0
#         trajectory.use_optimal_blending = False
#         trajectory.waypoints.append(waypoint)

#         try:
#             res = self.validate_waypoint_list(trajectory)
#         except rospy.ServiceException:
#             rospy.logerr("Failed to call ValidateWaypointList")
#             return False

#         error_number = len(res.output.trajectory_error_report.trajectory_error_elements)
#         MAX_ANGULAR_DURATION = 30

#         while (error_number >= 1 and angular_duration != MAX_ANGULAR_DURATION) :
#             angular_duration += 1
#             trajectory.waypoints[0].oneof_type_of_waypoint.angular_waypoint[0].duration = angular_duration

#             try:
#                 res = self.validate_waypoint_list(trajectory)
#             except rospy.ServiceException:
#                 rospy.logerr("Failed to call ValidateWaypointList")
#                 return False

#             error_number = len(res.output.trajectory_error_report.trajectory_error_elements)

#         if (angular_duration == MAX_ANGULAR_DURATION) :
#             # It should be possible to reach position within 30s
#             # WaypointList is invalid (other error than angularWaypoint duration)
#             rospy.loginfo("WaypointList is invalid")
#             return False

#         req.input.oneof_action_parameters.execute_waypoint_list.append(trajectory)
        
#         # Send the angles
#         rospy.loginfo("Sending the robot vertical...")
#         try:
#             self.execute_action(req)
#         except rospy.ServiceException:
#             rospy.logerr("Failed to call ExecuteWaypointjectory")
#             return False
#         else:
#             return self.wait_for_action_end_or_abort()

def main():
    rospy.init_node("base_controller", anonymous=True)
    bc_module = BaseController(True)

    rate = rospy.Rate(200)
    
    start = rospy.get_time()
    # main control loop
    while not rospy.is_shutdown() and bc_module.is_activated:
        # if not bc_module.is_activated:
        #     rospy.loginfo('Base controller is not activated.')
        #     rate.sleep()
        #     continue
        if rospy.get_time() - start < 333.0:
            #print("hi {}".format(rospy.get_time() - start))
            bc_module.loop_image()
            #bc_module.publish_joints([1.5]*6)
        else:
            #print("bye {}".format(rospy.get_time() - start))
            #bc_module.publish_joints([0]*6)
            #bc_module.loop_video()
            bc_module.loop_image()
        rate.sleep()
    rospy.signal_shutdown("Controller served its purpose.")


if __name__ == '__main__':
    try:
        main()
    except rospy.exceptions.ROSInterruptException:
        rospy.logerr(f'Shutting down peacefully due to a user interrupt.')
    else:
        rospy.logerr(f'Shutting down...')